首先可以用scripts/preprocessing文件夹下的get_similarity.py文件获取msrp.sts.url的相似性矩阵
也可以用我们已经构建好的矩阵，那么这步可以略过
然后运行preprocessing文件夹下 preprocess_msrp.py文件，数据预处理

最后
在scripts/training文件夹下运行
python main_msrp.py --proportion 0.1 --output 10

proportion 指定数据集大小，output决定输出模型到不同数据集对应的文件夹下，这里10就是10%数据

可以直接运行python main_msrp.py ，这时候使用默认100%的数据


Bert_sim
====
This repository restore the sorce code and datasets for "Using Prior Knowledge to Guide BERT’s Attention in Semantic Textual Matching Tasks"

ESIM
----
1.First, you can use the get_similarity.py file in the scripts/preprocessing folder to obtain the similarity matrix of the msrp/sts/url dataset. You can also use the matrix we have built, then this step can be skipped.
2.Then run the preprocess_msrp.py file in the preprocessing folder to preprocess the data
3.Run under the scripts/training folder python main_msrp.py --proportion 0.1 --output 10
Proportion specifies the size of the data set, output determines the output model to the folder corresponding to different data sets, where 10 is 10% of the data
You can run python main_msrp.py directly, and use the default 100% data at this time

[Here](https://drive.google.com/file/d/1KshPlBu7StLaASJOBsXzp4HTTYzR75CS/view?usp=sharing) is the data we have processed, Please place it under the ESIM/data/dataset folder after downloading